{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48fda00-4ca5-45c4-9cf4-93b8d21e51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mutual_info_score, normalized_mutual_info_score\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "df_vehicle = pd.read_csv('/Users/zjh/Downloads/datasets/vehicle.csv')\n",
    "df_accident = pd.read_csv('/Users/zjh/Downloads/datasets/accident.csv')\n",
    "\n",
    "# calculate car age\n",
    "df_accident['ACCIDENT_DATE'] = pd.to_datetime(df_accident['ACCIDENT_DATE'], errors='coerce')\n",
    "df_accident['ACCIDENT_YEAR'] = df_accident['ACCIDENT_DATE'].dt.year\n",
    "df_v = pd.merge(\n",
    "    df_vehicle[['ACCIDENT_NO','VEHICLE_ID','VEHICLE_YEAR_MANUF']],\n",
    "    df_accident[['ACCIDENT_NO','ACCIDENT_YEAR', 'SPEED_ZONE','SEVERITY']],\n",
    "    on='ACCIDENT_NO', how='inner'\n",
    ")\n",
    "# delete missing data\n",
    "df_v = df_v.dropna(subset=['VEHICLE_YEAR_MANUF', 'ACCIDENT_YEAR', 'SPEED_ZONE','SEVERITY'])\n",
    "#IQR-handle outlier\n",
    "for i in ['VEHICLE_YEAR_MANUF', 'ACCIDENT_YEAR', 'SPEED_ZONE']:\n",
    "    Q1 = df_v[i].quantile(0.25)\n",
    "    Q3 = df_v[i].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 3 * IQR\n",
    "    upper = Q3 + 3 * IQR\n",
    "    df_v = df_v[(df_v[i] >= lower) & (df_v[i] <= upper)].copy()\n",
    "\n",
    "df_v['VEHICLE_AGE'] = df_v['ACCIDENT_YEAR'] - df_v['VEHICLE_YEAR_MANUF']\n",
    "df_v = df_v[df_v['VEHICLE_AGE']>=0].copy()\n",
    "df = df_v[['ACCIDENT_NO','VEHICLE_ID','VEHICLE_AGE','SPEED_ZONE','SEVERITY']]\n",
    "\n",
    "# 读取数据\n",
    "data = df[[\"VEHICLE_AGE\", \"SPEED_ZONE\", \"SEVERITY\"]]  # 剔除标识符\n",
    "data.loc[:, 'VEHICLE_AGE'] = pd.to_numeric(data['VEHICLE_AGE'], errors='coerce')\n",
    "# 先使用pearson进行相关性分析\n",
    "\n",
    "corr_df = data[[\"SEVERITY\",\"SPEED_ZONE\",\"VEHICLE_AGE\"]].copy()\n",
    "correlation_matrix = corr_df.corr(method=\"pearson\").round(2)\n",
    "\n",
    "print(\"\\nPEARSON矩阵:\\n\", correlation_matrix)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(correlation_matrix,annot=True,cmap=\"coolwarm\",fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix (Pearson)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 定义目标变量（例如分析车辆年龄与事故严重程度的关系）\n",
    "target = data[\"SEVERITY\"]\n",
    "continuous_var = \"VEHICLE_AGE\"\n",
    "\n",
    "# ---------------------- 方法3：基于信息损失最小化选择分箱数 ----------------------\n",
    "def find_optimal_bins(data, target, min_bins=3, max_bins=100):\n",
    "    mi_scores = []\n",
    "    possible_bins = range(min_bins, max_bins + 1)\n",
    "    \n",
    "    for n_bins in possible_bins:\n",
    "        discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
    "        discretized = discretizer.fit_transform(data[[continuous_var]]).flatten()\n",
    "        mi = mutual_info_score(discretized, target)\n",
    "        mi_scores.append(mi)\n",
    "    \n",
    "    # 找到 MI 变化趋于稳定的分箱数（一阶导数变化最小）\n",
    "    diffs = np.diff(mi_scores)\n",
    "    optimal_bins = possible_bins[np.argmin(np.abs(diffs)) + 1]  # +1 因为diff后长度减1\n",
    "    return optimal_bins, mi_scores, possible_bins\n",
    "\n",
    "optimal_bins, mi_scores, possible_bins = find_optimal_bins(data[[continuous_var]], target)\n",
    "\n",
    "# 可视化 MI 随分箱数的变化\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(possible_bins, mi_scores, marker='o')\n",
    "plt.axvline(x=optimal_bins, color='r', linestyle='--', label=f'Optimal Bins = {optimal_bins}')\n",
    "plt.xlabel(\"Number of Bins\")\n",
    "plt.ylabel(\"Mutual Information (MI)\")\n",
    "plt.title(\"MI vs. Number of Bins\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------- 使用最佳分箱数离散化数据 ----------------------\n",
    "discretizer = KBinsDiscretizer(n_bins=optimal_bins, encode='ordinal', strategy='uniform')\n",
    "data_discretized = data.copy()\n",
    "data_discretized[continuous_var] = discretizer.fit_transform(data[[continuous_var]]).astype(int)\n",
    "\n",
    "# ---------------------- 计算 MI 和 NMI 矩阵 ----------------------\n",
    "def calculate_mi_matrix(df, discrete_vars):\n",
    "    mi_matrix = pd.DataFrame(index=discrete_vars, columns=discrete_vars)\n",
    "    for var1 in discrete_vars:\n",
    "        for var2 in discrete_vars:\n",
    "            mi = mutual_info_score(df[var1], df[var2])\n",
    "            mi_matrix.loc[var1, var2] = mi\n",
    "    return mi_matrix\n",
    "\n",
    "def calculate_nmi_matrix(df, discrete_vars):\n",
    "    nmi_matrix = pd.DataFrame(index=discrete_vars, columns=discrete_vars)\n",
    "    for var1 in discrete_vars:\n",
    "        for var2 in discrete_vars:\n",
    "            nmi = normalized_mutual_info_score(df[var1], df[var2])\n",
    "            nmi_matrix.loc[var1, var2] = nmi\n",
    "    return nmi_matrix\n",
    "\n",
    "# 定义分析变量（包含离散化后的连续变量）\n",
    "discrete_vars = [continuous_var, \"SPEED_ZONE\", \"SEVERITY\"]\n",
    "\n",
    "mi_matrix = calculate_mi_matrix(data_discretized, discrete_vars)\n",
    "nmi_matrix = calculate_nmi_matrix(data_discretized, discrete_vars)\n",
    "\n",
    "print(f\"最优分箱数: {optimal_bins}\\n\")\n",
    "print(\"MI矩阵:\\n\", mi_matrix)\n",
    "print(\"\\nNMI矩阵:\\n\", nmi_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = data[['SPEED_ZONE','VEHICLE_AGE']].astype(float)\n",
    "y = data['SEVERITY'].astype(int)\n",
    "\n",
    "# 2. 划分训练集和测试集（70% 训练 / 30% 测试），保持 Severity 类别比例\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. 特征标准化（对 Logistic Regression 很重要）\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc  = scaler.transform(X_test)\n",
    "\n",
    "# ===== Model 1: Logistic Regression =====\n",
    "lr = LogisticRegression(\n",
    "    class_weight='balanced',solver='lbfgs', max_iter=1000, random_state=42\n",
    ")\n",
    "lr.fit(X_train_sc, y_train)\n",
    "y_pred_lr = lr.predict(X_test_sc)\n",
    "\n",
    "# 评估\n",
    "print(\"===== Logistic Regression =====\")\n",
    "acclr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy :\", round(acclr, 3))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "# ===== Model 2: Random Forest =====\n",
    "rf = RandomForestClassifier(class_weight='balanced',n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)  # 随机森林对原始数值就好，不一定需要标准化\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# 评估\n",
    "print(\"\\n===== Random Forest =====\")\n",
    "accrf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy :\", round(accrf, 3))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "def main():\n",
    "    clusterdata = data[['SPEED_ZONE', 'VEHICLE_AGE']].copy()\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(clusterdata)\n",
    "\n",
    "    # 4. 肘部法则 (Elbow) —— 1 到 10 个簇\n",
    "    inertia = []\n",
    "    ks = range(1, 11)\n",
    "    for k in ks:\n",
    "        km = KMeans(n_clusters=k, random_state=42)\n",
    "        km.fit(X_scaled)\n",
    "        inertia.append(km.inertia_)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(ks, inertia, marker='o')\n",
    "    plt.title('Elbow Method for Optimal k')\n",
    "    plt.xlabel('Number of clusters k')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 5. 轮廓系数 (Silhouette) —— 2 到 10 个簇\n",
    "    sil_scores = []\n",
    "    ks2 = range(2, 11)\n",
    "    for k in ks2:\n",
    "        km = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = km.fit_predict(X_scaled)\n",
    "        sil_scores.append(silhouette_score(X_scaled, labels))\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(ks2, sil_scores, marker='o')\n",
    "    plt.title('Silhouette Scores for Various k')\n",
    "    plt.xlabel('Number of clusters k')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 6. 假设结合两图选定最佳 k = 3，进行最终聚类\n",
    "    best_k = 3\n",
    "    kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "    # 7. 可视化聚类结果\n",
    "    data['Cluster'] = clusters.astype(str)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for cluster in sorted(data['Cluster'].unique()):\n",
    "        subset = data[data['Cluster'] == cluster]\n",
    "        plt.scatter(subset['SPEED_ZONE'], subset['VEHICLE_AGE'],\n",
    "                    label=f'Cluster {cluster}', s=10, alpha=0.6)\n",
    "\n",
    "    # 标出簇中心（反标准化回原始刻度）\n",
    "    centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "    plt.scatter(centers[:, 0], centers[:, 1],\n",
    "                marker='X', s=200, c='black', label='Centroids')\n",
    "    plt.title('K-Means Clustering of Speed Zone and Vehicle Age')\n",
    "    plt.xlabel('Speed Zone')\n",
    "    plt.ylabel('Vehicle Age')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf9d61-6a09-430d-9d32-e1ce56e8e241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
